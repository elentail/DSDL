{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scans found: 4000 , Total Headers 4000\n"
     ]
    }
   ],
   "source": [
    "all_xray_df = pd.read_csv('./data/training_labels.csv')\n",
    "all_image_paths = {os.path.basename(x): x for x in \n",
    "                   glob(os.path.join( './data/training', '*.png'))}\n",
    "print('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\n",
    "all_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\n",
    "#all_xray_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_xray_df['Label'] = all_xray_df['Finding Labels'].map(lambda x: 0 if x=='No Finding' else 1.0)\n",
    "all_xray_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data shuffling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils  import shuffle\n",
    "\n",
    "\n",
    "\n",
    "normal =  all_xray_df [ all_xray_df['Label'] == 0.0 ]\n",
    "abnormal =  all_xray_df [ all_xray_df['Label'] == 1.0 ]\n",
    "\n",
    "X_train = pd.concat([normal.sample(frac=0.8, random_state=0),\\\n",
    "                     abnormal.sample(frac=0.8,random_state=0)], axis=0)\n",
    "X_valid = all_xray_df.loc[~all_xray_df.index.isin(X_train.index)]\n",
    "\n",
    "X_train = shuffle(X_train)\n",
    "X_valid = shuffle(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data agumentation\n",
    "- flip\n",
    "- random shfit\n",
    "- random affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "0.0    2560\n",
       "1.0    1280\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "out_path = './data/agument/'\n",
    "\n",
    "abnormal_df =  X_train [ X_train['Label'] == 1.0 ] \n",
    "\n",
    "if not os.path.exists(out_path):\n",
    "    os.mkdir(out_path)\n",
    "\n",
    "    for idx,row in abnormal_df.iterrows():\n",
    "        img = cv2.imread(row['path'],cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        # flip     \n",
    "        transform_img = cv2.flip(img,1)\n",
    "        cv2.imwrite(out_path+'F'+os.path.basename(row['path']),transform_img)\n",
    "\n",
    "        # random shift\n",
    "        rows,cols = img.shape\n",
    "        shift_var = np.random.randint(low=-6,high=6,size=2)\n",
    "        M = np.float32([[1,0,shift_var[0]],[0,1,shift_var[1]]])\n",
    "        transform_img = cv2.warpAffine(img,M,(cols,rows))\n",
    "        cv2.imwrite(out_path+'S'+os.path.basename(row['path']),transform_img)\n",
    "\n",
    "        # random affine\n",
    "        pts1 = np.float32([[8,8],[58,58],[32,58]])\n",
    "        shift_var = np.random.randint(low=-1,high=1,size=6).astype(np.float32) \n",
    "        pts2 = np.reshape(pts1.flatten()+shift_var,(-1,2))\n",
    "        \n",
    "        M = cv2.getAffineTransform(pts1,pts2)\n",
    "        transform_img = cv2.warpAffine(img,M,(cols,rows))        \n",
    "        cv2.imwrite(out_path+'A'+os.path.basename(row['path']),transform_img)\n",
    "\n",
    "\n",
    "    \n",
    "column_name = ['Image Index','Finding Labels','path','Label']\n",
    "data_list = []\n",
    "flist = glob.glob(out_path+'*.png')\n",
    "for f in flist:\n",
    "    path_name = f\n",
    "    base_name = os.path.basename(f)\n",
    "    data_list.append([base_name,'Effusion',path_name,1.0])\n",
    "\n",
    "flip_df = pd.DataFrame(columns=column_name,data=data_list)\n",
    "\n",
    "\n",
    "X_train = pd.concat([X_train,flip_df])\n",
    "X_train.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3840, 800)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = X_train['path'].values\n",
    "train_y = X_train['Label'].values\n",
    "\n",
    "train_image = []\n",
    "for f in train_x:\n",
    "    img = cv2.imread(f,cv2.IMREAD_GRAYSCALE)\n",
    "    m,s = cv2.meanStdDev(img)\n",
    "    std_img = (img- m)/(1.e-6 + s)\n",
    "    \n",
    "    train_image.append(std_img.reshape((64,64,1)))\n",
    "    \n",
    "train_label = np.column_stack([1-train_y,train_y])\n",
    "\n",
    "\n",
    "valid_x = X_valid['path'].values\n",
    "valid_y = X_valid['Label'].values\n",
    "\n",
    "valid_image = []\n",
    "for f in valid_x:\n",
    "    img = cv2.imread(f,cv2.IMREAD_GRAYSCALE)\n",
    "    m,s = cv2.meanStdDev(img)\n",
    "    std_img = (img- m)/(1.e-6 + s)\n",
    "    valid_image.append(std_img.reshape((64,64,1)))\n",
    "    \n",
    "valid_label = np.column_stack([1-valid_y,valid_y])\n",
    "len(train_x),len(valid_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Residual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "xavi_init = tf.contrib.layers.xavier_initializer\n",
    "\n",
    "\n",
    "class resnet():\n",
    "    \n",
    "    #xavi_init = tf.contrib.layers.xavier_initializer\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    \n",
    "    def short_layer(self,input_data,is_train,name,ksize=3):\n",
    "        shapes = input_data.get_shape().as_list()\n",
    "        with tf.name_scope('name'):\n",
    "            norm1 = tf.layers.batch_normalization(input_data,training=is_train)\n",
    "            batn1 = tf.nn.relu(norm1)\n",
    "            \n",
    "            weit1 = tf.get_variable(name+'_w1',shape=[ksize,ksize,shapes[-1],shapes[-1]],initializer=xavi_init())\n",
    "            conv1 = tf.nn.conv2d(batn1,weit1,strides=[1,1,1,1],padding='SAME')\n",
    "            \n",
    "            \n",
    "            norm2 = tf.layers.batch_normalization(conv1,training=is_train)\n",
    "            batn2 = tf.nn.relu(norm2)\n",
    "            \n",
    "            weit2 = tf.get_variable(name+'_w2',shape=[ksize,ksize,shapes[-1],shapes[-1]],initializer=xavi_init())\n",
    "            conv2 = tf.nn.conv2d(batn2,weit2,strides=[1,1,1,1],padding='SAME')\n",
    "            \n",
    "        return input_data + conv2\n",
    "    \n",
    "    \n",
    "    def build_model(self,data,train_mode):\n",
    "        \n",
    "        # input 64,64,1\n",
    "        with tf.name_scope(\"conv_layer1\"):\n",
    "            \n",
    "            # conv1 - 5,5 64 ,stride\n",
    "            net = tf.layers.conv2d(data,32,kernel_size=5,activation=tf.nn.relu,padding='same')     \n",
    "            \n",
    "            # batch , 64,64,32\n",
    "            net = tf.layers.batch_normalization(net, training=train_mode)\n",
    "            \n",
    "            # Max pool 32,32,32\n",
    "            net = tf.layers.max_pooling2d(net, pool_size=3, strides=2, padding='same')\n",
    "            \n",
    "            \n",
    "        short1_1 = self.short_layer(net,train_mode,'short1_1')\n",
    "        short1_2 = self.short_layer(short1_1,train_mode,'short1_2')\n",
    "        short2_1 = self.short_layer(short1_2,train_mode,'short2_1')\n",
    "        short2_2 = self.short_layer(short2_1,train_mode,'short2_2')\n",
    "        \n",
    "        \n",
    "        # input 32,32,32\n",
    "        with tf.name_scope(\"conv_layer2\"):\n",
    "            \n",
    "            # conv1 - 3,3 64 ,stride\n",
    "            net = tf.layers.conv2d(short2_2,64,kernel_size=3,activation=tf.nn.relu,padding='same')     \n",
    "            \n",
    "            # batch , 32,32,64\n",
    "            net = tf.layers.batch_normalization(net, training=train_mode)        \n",
    "        \n",
    "            # Max pool 16,16,64\n",
    "            net = tf.layers.max_pooling2d(net, pool_size=3, strides=2, padding='same')        \n",
    "        \n",
    "        short3 = self.short_layer(net,train_mode,'short3')\n",
    "        short4 = self.short_layer(short3,train_mode,'short4')     \n",
    "        \n",
    "        \n",
    "        # input 16,16,64\n",
    "        with tf.name_scope(\"conv_layer2\"):\n",
    "            \n",
    "            # conv1 - 3,3 128 ,stride\n",
    "            net = tf.layers.conv2d(short4,128,kernel_size=3,activation=tf.nn.relu,padding='same')     \n",
    "            \n",
    "            # batch , 16,16,128\n",
    "            net = tf.layers.batch_normalization(net, training=train_mode)        \n",
    "        \n",
    "            # Max pool 8,8,128\n",
    "            net = tf.layers.max_pooling2d(net, pool_size=3, strides=2, padding='same')        \n",
    "        \n",
    "        short5 = self.short_layer(net,train_mode,'short5')\n",
    "        short6 = self.short_layer(short5,train_mode,'short6')     \n",
    "        \n",
    "        \n",
    "        # input 8,8,128\n",
    "        with tf.name_scope(\"conv_layer2\"):\n",
    "            \n",
    "            # conv1 - 3,3 256 ,stride\n",
    "            net = tf.layers.conv2d(short6,256,kernel_size=3,activation=tf.nn.relu,padding='same')     \n",
    "            \n",
    "            # batch , 8,8,256\n",
    "            net = tf.layers.batch_normalization(net, training=train_mode)        \n",
    "        \n",
    "            # Max pool 4,4,256\n",
    "            net = tf.layers.max_pooling2d(net, pool_size=3, strides=2, padding='same')        \n",
    "        \n",
    "        short7 = self.short_layer(net,train_mode,'short7')\n",
    "        short8 = self.short_layer(short7,train_mode,'short8')\n",
    " \n",
    "        short9 = self.short_layer(short8,train_mode,'short9')\n",
    "        short10 = self.short_layer(short7,train_mode,'short10')\n",
    "        \n",
    "        \n",
    "        \n",
    "        return self.global_logit(short10,2)\n",
    "\n",
    "        \n",
    "        \n",
    "    def global_logit(self,input_data,output):\n",
    "        shapes = input_data.get_shape().as_list()\n",
    "        \n",
    "        net = tf.nn.avg_pool(input_data,ksize=[1, shapes[1], shapes[2], 1],\\\n",
    "                       strides=[1, 1, 1, 1],padding='VALID')\n",
    "        \n",
    "        net_shape = net.get_shape().as_list()\n",
    "        net = tf.reshape(net, [-1, net_shape[1] * net_shape[2] * net_shape[3]])     \n",
    "        \n",
    "        logits = tf.layers.dense(net,output, activation=None)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    \n",
    "    def model_loss(self,logits,labels):\n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=labels)\n",
    "        cross_mean = tf.reduce_mean(cross_entropy)\n",
    "        return cross_mean\n",
    "        \n",
    "    def model_train(self,loss,lr=0.001):\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = tf.train.AdamOptimizer(lr).minimize(total_loss)\n",
    "        return train_op\n",
    "    \n",
    "    def model_accuracy(self,logits,labels):\n",
    "        correct_prediction = tf.equal(tf.argmax(logits, 1),tf.argmax(labels, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        return accuracy\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = tf.placeholder(tf.float32, [None, 64, 64, 1])\n",
    "true_out = tf.placeholder(tf.float32, [ None, 2])\n",
    "\n",
    "logits = model.build_model(images,True)\n",
    "total_loss = model.model_loss(logits,true_out)\n",
    "train_op = model.model_train(total_loss)\n",
    "accuracy = model.model_accuracy(logits,true_out)\n",
    "\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 256.2241123363287\n",
      "1 247.6848957762515\n",
      "2 199.30341632756443\n",
      "3 199.00564997095023\n",
      "4 189.0108185714202\n",
      "5 205.71745093376785\n",
      "6 197.52500757422138\n",
      "7 223.47771237892448\n",
      "8 204.8818228602825\n",
      "9 198.2455785470047\n",
      "10 200.65268731988363\n",
      "11 200.230513742171\n",
      "12 207.02938389685005\n",
      "13 180.19040175874702\n",
      "14 193.5778093654153\n",
      "15 196.37503647757694\n",
      "16 186.84158028777452\n",
      "17 193.0247954364266\n",
      "18 198.24318517785287\n",
      "19 191.63254484131176\n",
      "20 194.4249158962739\n",
      "21 193.15861309098545\n",
      "22 192.1747417319566\n",
      "23 189.32753314974252\n",
      "24 190.40872025046602\n",
      "25 192.77055697949254\n",
      "26 197.9760133238742\n",
      "27 192.15308568614398\n",
      "28 193.32766973623075\n",
      "29 179.7538320165404\n",
      "30 190.95973648899235\n",
      "31 184.92916141136084\n",
      "32 186.1395695757128\n",
      "33 200.95252821512986\n",
      "34 200.89231747062877\n",
      "35 189.47332913405262\n",
      "36 202.0673078079708\n",
      "37 205.33849233668298\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-503105e0540f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mlabel_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mimage_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlabel_iter\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorgpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorgpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorgpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorgpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorgpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tensorgpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#batch_size = 500\n",
    "batch_size = 10\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for epoch in range(350):\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for start in range(0,len(train_image),batch_size):\n",
    "\n",
    "            end = min( start+batch_size ,len(train_image))\n",
    "            image_iter = train_image[start:end]\n",
    "            label_iter = train_label[start:end]\n",
    "\n",
    "            _,train_loss = sess.run([train_op,total_loss], feed_dict={images: image_iter, true_out:label_iter})\n",
    "            epoch_loss += train_loss\n",
    "\n",
    "            if end == len(train_image) :\n",
    "                #loss,accr = sess.run([accuracy], feed_dict={images: image_iter,true_out:label_iter})\n",
    "                print(epoch,epoch_loss)\n",
    "\n",
    "            \n",
    "    #saver.save(sess, CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"This example builds deep residual network for mnist data.\n",
    "Reference Paper: http://arxiv.org/pdf/1512.03385.pdf\n",
    "Note that this is still a work-in-progress. Feel free to submit a PR\n",
    "to make this better.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from collections import namedtuple\n",
    "from math import sqrt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "N_DIGITS = 10  # Number of digits.\n",
    "X_FEATURE = 'x'  # Name of the input feature.\n",
    "\n",
    "\n",
    "def res_net_model(features, labels, mode):\n",
    "  \"\"\"Builds a residual network.\"\"\"\n",
    "\n",
    "  # Configurations for each bottleneck group.\n",
    "  BottleneckGroup = namedtuple('BottleneckGroup',\n",
    "                               ['num_blocks', 'num_filters', 'bottleneck_size'])\n",
    "  groups = [\n",
    "      BottleneckGroup(3, 128, 32), BottleneckGroup(3, 256, 64),\n",
    "      BottleneckGroup(3, 512, 128), BottleneckGroup(3, 1024, 256)\n",
    "  ]\n",
    "\n",
    "  x = features[X_FEATURE]\n",
    "  input_shape = x.get_shape().as_list()\n",
    "\n",
    "  # Reshape the input into the right shape if it's 2D tensor\n",
    "  if len(input_shape) == 2:\n",
    "    ndim = int(sqrt(input_shape[1]))\n",
    "    x = tf.reshape(x, [-1, ndim, ndim, 1])\n",
    "\n",
    "  training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "  \n",
    "  # First convolution expands to 64 channels\n",
    "  with tf.variable_scope('conv_layer1'):\n",
    "    net = tf.layers.conv2d(\n",
    "        x,\n",
    "        filters=64,\n",
    "        kernel_size=7,\n",
    "        activation=tf.nn.relu)\n",
    "    net = tf.layers.batch_normalization(net, training=training)\n",
    "\n",
    "  # Max pool\n",
    "  net = tf.layers.max_pooling2d(\n",
    "      net, pool_size=3, strides=2, padding='same')\n",
    "\n",
    "  # First chain of resnets\n",
    "  with tf.variable_scope('conv_layer2'):\n",
    "    net = tf.layers.conv2d(\n",
    "        net,\n",
    "        filters=groups[0].num_filters,\n",
    "        kernel_size=1,\n",
    "        padding='valid')\n",
    "\n",
    "  # Create the bottleneck groups, each of which contains `num_blocks`\n",
    "  # bottleneck groups.\n",
    "  for group_i, group in enumerate(groups):\n",
    "    for block_i in range(group.num_blocks):\n",
    "      name = 'group_%d/block_%d' % (group_i, block_i)\n",
    "\n",
    "      # 1x1 convolution responsible for reducing dimension\n",
    "      with tf.variable_scope(name + '/conv_in'):\n",
    "        conv = tf.layers.conv2d(\n",
    "            net,\n",
    "            filters=group.num_filters,\n",
    "            kernel_size=1,\n",
    "            padding='valid',\n",
    "            activation=tf.nn.relu)\n",
    "        conv = tf.layers.batch_normalization(conv, training=training)\n",
    "\n",
    "      with tf.variable_scope(name + '/conv_bottleneck'):\n",
    "        conv = tf.layers.conv2d(\n",
    "            conv,\n",
    "            filters=group.bottleneck_size,\n",
    "            kernel_size=3,\n",
    "            padding='same',\n",
    "            activation=tf.nn.relu)\n",
    "        conv = tf.layers.batch_normalization(conv, training=training)\n",
    "\n",
    "      # 1x1 convolution responsible for restoring dimension\n",
    "      with tf.variable_scope(name + '/conv_out'):\n",
    "        input_dim = net.get_shape()[-1].value\n",
    "        conv = tf.layers.conv2d(\n",
    "            conv,\n",
    "            filters=input_dim,\n",
    "            kernel_size=1,\n",
    "            padding='valid',\n",
    "            activation=tf.nn.relu)\n",
    "        conv = tf.layers.batch_normalization(conv, training=training)\n",
    "\n",
    "      # shortcut connections that turn the network into its counterpart\n",
    "      # residual function (identity shortcut)\n",
    "      net = conv + net\n",
    "\n",
    "    try:\n",
    "      # upscale to the next group size\n",
    "      next_group = groups[group_i + 1]\n",
    "      with tf.variable_scope('block_%d/conv_upscale' % group_i):\n",
    "        net = tf.layers.conv2d(\n",
    "            net,\n",
    "            filters=next_group.num_filters,\n",
    "            kernel_size=1,\n",
    "            padding='same',\n",
    "            activation=None,\n",
    "            bias_initializer=None)\n",
    "    except IndexError:\n",
    "      pass\n",
    "\n",
    "  net_shape = net.get_shape().as_list()\n",
    "  net = tf.nn.avg_pool(\n",
    "      net,\n",
    "      ksize=[1, net_shape[1], net_shape[2], 1],\n",
    "      strides=[1, 1, 1, 1],\n",
    "      padding='VALID')\n",
    "\n",
    "  net_shape = net.get_shape().as_list()\n",
    "  net = tf.reshape(net, [-1, net_shape[1] * net_shape[2] * net_shape[3]])\n",
    "\n",
    "  # Compute logits (1 per class) and compute loss.\n",
    "  logits = tf.layers.dense(net, N_DIGITS, activation=None)\n",
    "\n",
    "  # Compute predictions.\n",
    "  predicted_classes = tf.argmax(logits, 1)\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    predictions = {\n",
    "        'class': predicted_classes,\n",
    "        'prob': tf.nn.softmax(logits)\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "  # Compute loss.\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Create training op.\n",
    "  if training:\n",
    "    optimizer = tf.train.AdagradOptimizer(learning_rate=0.01)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Compute evaluation metrics.\n",
    "  eval_metric_ops = {\n",
    "      'accuracy': tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predicted_classes)\n",
    "  }\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "def main(unused_args):\n",
    "  # Download and load MNIST data.\n",
    "  mnist = tf.contrib.learn.datasets.DATASETS['mnist']('/tmp/mnist')\n",
    "\n",
    "  # Create a new resnet classifier.\n",
    "  classifier = tf.estimator.Estimator(model_fn=res_net_model)\n",
    "\n",
    "  tf.logging.set_verbosity(tf.logging.INFO)  # Show training logs.\n",
    "\n",
    "  # Train model and save summaries into logdir.\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={X_FEATURE: mnist.train.images},\n",
    "      y=mnist.train.labels.astype(np.int32),\n",
    "      batch_size=100,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "  classifier.train(input_fn=train_input_fn, steps=100)\n",
    "\n",
    "  # Calculate accuracy.\n",
    "  test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={X_FEATURE: mnist.test.images},\n",
    "      y=mnist.test.labels.astype(np.int32),\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "  scores = classifier.evaluate(input_fn=test_input_fn)\n",
    "  print('Accuracy: {0:f}'.format(scores['accuracy']))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorgpu",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
