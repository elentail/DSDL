{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "df = pd.read_csv('./data/creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...         V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...   -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ...   -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...    0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ...   -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...   -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fraud = df[df.Class == 1]\n",
    "normal = df[df.Class == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([fraud.sample(frac=0.8, \n",
    "                                  random_state=0), \n",
    "                     normal.sample(frac=0.8,\n",
    "                                  random_state=0)], \n",
    "                    axis=0)\n",
    "X_test = df.loc[~df.index.isin(X_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train = shuffle(X_train, random_state=0)\n",
    "X_test = shuffle(X_test, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "y_train = np.zeros((X_train.shape[0], 2),  dtype=float)\n",
    "y_train[:, 1] = X_train.Class\n",
    "y_train[:, 0] = 1 - y_train[:, 1]\n",
    "\n",
    "y_test = np.zeros((X_test.shape[0], 2), dtype=float)\n",
    "y_test[:, 1] = X_test.Class\n",
    "y_test[:, 0] = 1 - y_test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ratio = len(X_train) / len(X_train[X_train.Class == 1]) \n",
    "\n",
    "#y_train[:, 1] *= ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = X_train.columns.values\n",
    "for feature in features:\n",
    "    mean = df[feature].mean()\n",
    "    std = df[feature].std()\n",
    "    X_train.loc[:, feature] = \\\n",
    "        (X_train[feature] - mean) / std\n",
    "    X_test.loc[:, feature] = \\\n",
    "        (X_test[feature] - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fields = ['Class']\n",
    "X_train = X_train.drop(fields, axis=1)\n",
    "X_test = X_test.drop(fields, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "split = (X_train.shape[0] * 7) // 8\n",
    "\n",
    "inputX = X_train.as_matrix()[:split]\n",
    "inputX_valid = X_train.as_matrix()[split:]\n",
    "inputX_test = X_test.as_matrix()\n",
    "\n",
    "inputY = y_train[:split]\n",
    "inputY_valid = y_train[split:]\n",
    "inputY_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_nodes1 = 60\n",
    "hidden_nodes2 = 30\n",
    "hidden_nodes3 = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_nodes = inputX.shape[1]\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, input_nodes])\n",
    "y_ = tf.placeholder(tf.float32, [None, 2])\n",
    "pkeep = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.zeros([input_nodes, \n",
    "                           hidden_nodes1]))\n",
    "b1 = tf.Variable(tf.zeros([hidden_nodes1]))\n",
    "y1 = tf.nn.sigmoid(tf.matmul(x, W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W2 = tf.Variable(tf.zeros([hidden_nodes1, \n",
    "                           hidden_nodes2]))\n",
    "b2 = tf.Variable(tf.zeros([hidden_nodes2]))\n",
    "y2 = tf.nn.sigmoid(tf.matmul(y1, W2) + b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W3 = tf.Variable(tf.zeros([hidden_nodes2, \n",
    "                           hidden_nodes3])) \n",
    "b3 = tf.Variable(tf.zeros([hidden_nodes3]))\n",
    "y3 = tf.nn.sigmoid(tf.matmul(y2, W3) + b3)\n",
    "y3 = tf.nn.dropout(y3, pkeep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W4 = tf.Variable(tf.zeros([hidden_nodes3, 2])) \n",
    "b4 = tf.Variable(tf.zeros([2]))\n",
    "y4 = tf.nn.softmax(tf.matmul(y3, W4) + b4)\n",
    "y = y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.005\n",
    "cost = -tf.reduce_sum(y_ * tf.log(y))\n",
    "optimizer = tf.train.AdamOptimizer(0.005)\n",
    "optimizer = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = tf.argmax(y_, 1)\n",
    "predictions = tf.argmax(y, 1)\n",
    "correct = tf.equal(labels, predictions)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_, pre_op = tf.metrics.precision(labels, predictions)\n",
    "_, rec_op = tf.metrics.recall(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_epoch(epoch):\n",
    "    trn_res = sess.run([accuracy, pre_op, rec_op, cost],\n",
    "                       feed_dict={x: inputX, \n",
    "                                  y_: inputY,\n",
    "                                  pkeep: dropout})\n",
    "    vld_res = sess.run([accuracy, pre_op, rec_op, cost], \n",
    "                       feed_dict={x: inputX_valid, \n",
    "                                  y_: inputY_valid,\n",
    "                                  pkeep: 1})\n",
    "    test_res = sess.run([accuracy, pre_op, rec_op, cost], \n",
    "                       feed_dict={x: inputX_test, \n",
    "                                  y_: inputY_test,\n",
    "                                  pkeep: 1})    \n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    print('Training (acc={:.4f}, prec={:.4f}, '\n",
    "          'recall={:.4f}, cost={:.1f})'.format(*trn_res))\n",
    "    print('Validation (acc={:.4f}, prec={:.4f}, '\n",
    "          'recall={:.4f}, cost={:.1f})'.format(*vld_res))\n",
    "    print('Test (acc={:.4f}, prec={:.4f}, '\n",
    "          'recall={:.4f}, cost={:.1f})\\n'.format(*test_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "n_samples = inputY.shape[0]\n",
    "batch_size = 2048\n",
    "n_batches = n_samples // batch_size\n",
    "dropout = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Training (acc=0.9983, prec=0.0000, recall=0.0000, cost=2861.1)\n",
      "Validation (acc=0.9982, prec=0.0000, recall=0.0000, cost=404.0)\n",
      "Test (acc=0.9983, prec=0.0000, recall=0.0000, cost=787.5)\n",
      "\n",
      "Epoch: 5\n",
      "Training (acc=0.9983, prec=0.0000, recall=0.0000, cost=2100.6)\n",
      "Validation (acc=0.9982, prec=0.0000, recall=0.0000, cost=301.8)\n",
      "Test (acc=0.9983, prec=0.0000, recall=0.0000, cost=581.7)\n",
      "\n",
      "Epoch: 10\n",
      "Training (acc=0.9983, prec=0.0000, recall=0.0000, cost=1492.8)\n",
      "Validation (acc=0.9982, prec=0.0000, recall=0.0000, cost=216.6)\n",
      "Test (acc=0.9983, prec=0.0000, recall=0.0000, cost=413.1)\n",
      "\n",
      "Epoch: 15\n",
      "Training (acc=0.9983, prec=0.0000, recall=0.0000, cost=1047.9)\n",
      "Validation (acc=0.9982, prec=0.0000, recall=0.0000, cost=153.2)\n",
      "Test (acc=0.9983, prec=0.0000, recall=0.0000, cost=287.7)\n",
      "\n",
      "Epoch: 20\n",
      "Training (acc=0.9983, prec=0.0000, recall=0.0000, cost=838.8)\n",
      "Validation (acc=0.9982, prec=0.0000, recall=0.0000, cost=126.0)\n",
      "Test (acc=0.9983, prec=0.0000, recall=0.0000, cost=230.4)\n",
      "\n",
      "Epoch: 25\n",
      "Training (acc=0.9983, prec=0.0000, recall=0.0000, cost=741.7)\n",
      "Validation (acc=0.9982, prec=0.0000, recall=0.0000, cost=113.4)\n",
      "Test (acc=0.9983, prec=0.0000, recall=0.0000, cost=206.4)\n",
      "\n",
      "Epoch: 30\n",
      "Training (acc=0.9983, prec=1.0000, recall=0.0024, cost=693.0)\n",
      "Validation (acc=0.9982, prec=1.0000, recall=0.0024, cost=110.6)\n",
      "Test (acc=0.9983, prec=1.0000, recall=0.0023, cost=200.2)\n",
      "\n",
      "Epoch: 35\n",
      "Training (acc=0.9993, prec=0.8080, recall=0.0745, cost=663.8)\n",
      "Validation (acc=0.9993, prec=0.8111, recall=0.0839, cost=106.3)\n",
      "Test (acc=0.9994, prec=0.8121, recall=0.1021, cost=195.3)\n",
      "\n",
      "Epoch: 40\n",
      "Training (acc=0.9993, prec=0.7993, recall=0.1610, cost=639.4)\n",
      "Validation (acc=0.9993, prec=0.7989, recall=0.1688, cost=103.6)\n",
      "Test (acc=0.9993, prec=0.7961, recall=0.1834, cost=188.7)\n",
      "\n",
      "Epoch: 45\n",
      "Training (acc=0.9993, prec=0.7908, recall=0.2306, cost=628.2)\n",
      "Validation (acc=0.9992, prec=0.7898, recall=0.2368, cost=103.2)\n",
      "Test (acc=0.9992, prec=0.7851, recall=0.2488, cost=187.2)\n",
      "\n",
      "Epoch: 50\n",
      "Training (acc=0.9993, prec=0.7808, recall=0.2877, cost=624.7)\n",
      "Validation (acc=0.9993, prec=0.7807, recall=0.2928, cost=104.2)\n",
      "Test (acc=0.9992, prec=0.7771, recall=0.3028, cost=186.1)\n",
      "\n",
      "Epoch: 55\n",
      "Training (acc=0.9993, prec=0.7755, recall=0.3350, cost=605.9)\n",
      "Validation (acc=0.9993, prec=0.7756, recall=0.3393, cost=100.8)\n",
      "Test (acc=0.9992, prec=0.7733, recall=0.3477, cost=181.8)\n",
      "\n",
      "Epoch: 60\n",
      "Training (acc=0.9993, prec=0.7744, recall=0.3747, cost=586.7)\n",
      "Validation (acc=0.9992, prec=0.7742, recall=0.3784, cost=102.1)\n",
      "Test (acc=0.9992, prec=0.7733, recall=0.3856, cost=178.9)\n",
      "\n",
      "Epoch: 65\n",
      "Training (acc=0.9993, prec=0.7753, recall=0.4085, cost=592.3)\n",
      "Validation (acc=0.9993, prec=0.7757, recall=0.4116, cost=99.5)\n",
      "Test (acc=0.9992, prec=0.7746, recall=0.4177, cost=177.7)\n",
      "\n",
      "Epoch: 70\n",
      "Training (acc=0.9994, prec=0.7766, recall=0.4376, cost=588.1)\n",
      "Validation (acc=0.9993, prec=0.7768, recall=0.4403, cost=99.5)\n",
      "Test (acc=0.9992, prec=0.7762, recall=0.4455, cost=175.6)\n",
      "\n",
      "Epoch: 75\n",
      "Training (acc=0.9994, prec=0.7784, recall=0.4630, cost=599.4)\n",
      "Validation (acc=0.9994, prec=0.7789, recall=0.4654, cost=97.7)\n",
      "Test (acc=0.9993, prec=0.7788, recall=0.4700, cost=175.0)\n",
      "\n",
      "Epoch: 80\n",
      "Training (acc=0.9994, prec=0.7810, recall=0.4855, cost=576.1)\n",
      "Validation (acc=0.9993, prec=0.7813, recall=0.4875, cost=98.9)\n",
      "Test (acc=0.9993, prec=0.7810, recall=0.4916, cost=174.9)\n",
      "\n",
      "Epoch: 85\n",
      "Training (acc=0.9994, prec=0.7833, recall=0.5052, cost=576.9)\n",
      "Validation (acc=0.9994, prec=0.7837, recall=0.5071, cost=98.1)\n",
      "Test (acc=0.9993, prec=0.7835, recall=0.5107, cost=174.0)\n",
      "\n",
      "Epoch: 90\n",
      "Training (acc=0.9994, prec=0.7853, recall=0.5228, cost=584.2)\n",
      "Validation (acc=0.9994, prec=0.7857, recall=0.5244, cost=96.0)\n",
      "Test (acc=0.9993, prec=0.7856, recall=0.5276, cost=172.7)\n",
      "\n",
      "Epoch: 95\n",
      "Training (acc=0.9994, prec=0.7872, recall=0.5383, cost=578.2)\n",
      "Validation (acc=0.9994, prec=0.7876, recall=0.5398, cost=94.7)\n",
      "Test (acc=0.9993, prec=0.7876, recall=0.5428, cost=169.8)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "    for epoch in range(n_epochs): \n",
    "        for batch in range(n_batches):\n",
    "            idx1 = batch * batch_size\n",
    "            idx2 = (1 + batch) * batch_size\n",
    "            batch_x = inputX[idx1:idx2]\n",
    "            batch_y = inputY[idx1:idx2]\n",
    "\n",
    "            sess.run([optimizer], feed_dict={\n",
    "                x: batch_x, y_: batch_y, pkeep: dropout})\n",
    "            \n",
    "        if epoch % 5 == 0:\n",
    "            print_epoch(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = pd.concat([normal.sample(frac=0.8,\n",
    "                                   random_state=0)], \n",
    "                    axis=0)\n",
    "X_test = df.loc[~df.index.isin(X_train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
